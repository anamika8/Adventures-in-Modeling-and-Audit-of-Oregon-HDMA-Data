{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "koupaUKc_L2g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xFlcYdj_QZp",
        "outputId": "be23241a-5baf-475d-8244-29ab1492ae3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement"
      ],
      "metadata": {
        "id": "DFdlTOcY_TM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "\"The Home Mortgage Disclosure Act (HMDA) requires many financial institutions to maintain, report, and publicly disclose loan-level information about mortgages. These data help show whether lenders are serving the housing needs of their communities; they give public officials information that helps them make decisions and policies; and they shed light on lending patterns that could be discriminatory. The public data are modified to protect applicant and borrower privacy.\n",
        "\n",
        "HMDA was originally enacted by Congress in 1975 and is implemented by Regulation C.\" - [source](https://www.consumerfinance.gov/data-research/hmda/)"
      ],
      "metadata": {
        "id": "1qR_VSA1_WXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        "\n",
        "[Download the Dataset](https://ffiec.cfpb.gov/data-browser/data/2021?category=states&items=OR)\n",
        "\n",
        "[2021 HMDI Documentation](https://ffiec.cfpb.gov/documentation/2021/)\n",
        "\n",
        "[2021 data-feild specification](https://ffiec.cfpb.gov/documentation/2021/lar-data-fields/)\n",
        "\n",
        "[2021 HMDA Guide](https://www.ffiec.gov/hmda/pdf/2021Guide.pdf)"
      ],
      "metadata": {
        "id": "fOYg8nuK_bE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Design\n",
        "\n",
        "classifier 1: predict \"action taken\" column which is either\n",
        "\n",
        "\n",
        "* Labels\n",
        "    * Positive\n",
        "        * code 1 - Loan originated \n",
        "        * code 2 - Approved but not accepted \n",
        "          (Note: this counts, because we are focused on loan /approval/, more than loans approved-and-accepted)\n",
        "    * Negative\n",
        "        * code 3 - Loan Denied \n",
        "          (See denail-reason for more information)\n",
        "\n",
        "\n",
        "* Feature columns\n",
        "    * Business_or_commercial_purpose\n",
        "    * loan_to_value_ratio (aka Combined_loan_to_value_ratio)\n",
        "    * interest_rate\n",
        "    * hoepa_status\n",
        "    * loan_term\n",
        "    * property_value\n",
        "    * construction_method\n",
        "    * property_value\n",
        "    * occupancy_type\n",
        "    * income\n",
        "    * debt_to_income_ratio\n",
        "    * submission_of_application\n",
        "    * aus-1\n",
        "\n",
        "\n",
        "* protected classes:\n",
        "    * race\n",
        "    * ethnicity\n",
        "    * gender\n",
        "    * age\n",
        "    * tract_minority_population_percent\n",
        "    * other \"tract\" columns"
      ],
      "metadata": {
        "id": "WaBuSuGs_iLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "0eGwxSXC_jf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/'"
      ],
      "metadata": {
        "id": "UUGsdIU1_XiM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2021 = pd.read_csv(path + '2021_state_OR.csv')\n",
        "df_2020 = pd.read_csv(path + '2020_state_OR.csv')\n",
        "df_2019 = pd.read_csv(path + '2019_state_OR.csv')\n",
        "df_2018 = pd.read_csv(path + '2018_state_OR.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY_HeBBz_rwG",
        "outputId": "0ce10793-57ef-415e-fcd5-81af92218d2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-bff08d619a5e>:1: DtypeWarning: Columns (5,22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_2021 = pd.read_csv(path + '2021_state_OR.csv')\n",
            "<ipython-input-4-bff08d619a5e>:2: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_2020 = pd.read_csv(path + '2020_state_OR.csv')\n",
            "<ipython-input-4-bff08d619a5e>:3: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_2019 = pd.read_csv(path + '2019_state_OR.csv')\n",
            "<ipython-input-4-bff08d619a5e>:4: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_2018 = pd.read_csv(path + '2018_state_OR.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"df_2021 = {len(df_2021)}\")\n",
        "print(f\"df_2020 = {len(df_2020)}\")\n",
        "print(f\"df_2019 = {len(df_2019)}\")\n",
        "print(f\"df_2018 = {len(df_2018)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFntjLHW_67c",
        "outputId": "edf64b67-e649-462e-cade-58e935258bc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_2021 = 391601\n",
            "df_2020 = 400029\n",
            "df_2019 = 265274\n",
            "df_2018 = 229722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, col in enumerate(df_2021.columns):\n",
        "    \n",
        "    if(df_2020.columns[i] != col):\n",
        "        print(f\"df_2021[{i:02.0f}] = {col}\")\n",
        "        print(f\"df_2020[{i:02.0f}] = {df_2020.columns[i]}\")\n",
        "    if(df_2019.columns[i] != col):\n",
        "        print(f\"df_2021[{i:02.0f}] = {col}\")\n",
        "        print(f\"df_2019[{i:02.0f}] = {df_2019.columns[i]}\")\n",
        "    if(df_2018.columns[i] != col):\n",
        "        print(f\"df_2021[{i:02.0f}] = {col}\")\n",
        "        print(f\"df_2018[{i:02.0f}] = {df_2018.columns[i]}\")"
      ],
      "metadata": {
        "id": "zGFefUeX__lW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df_2021, df_2020, df_2019, df_2018]\n",
        "df_read = pd.concat(frames).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wVB1oSpfAEAM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_read[[\n",
        "        # Label Field\n",
        "        'action_taken',\n",
        "\n",
        "        # Input Fields\n",
        "        'loan_type',\n",
        "        'loan_purpose',\n",
        "        'business_or_commercial_purpose',\n",
        "        'loan_to_value_ratio',\n",
        "        'interest_rate',\n",
        "        'hoepa_status',\n",
        "        'loan_term',\n",
        "        'property_value',\n",
        "        'construction_method',\n",
        "        'occupancy_type',\n",
        "        'income',\n",
        "        'debt_to_income_ratio',\n",
        "        'submission_of_application',\n",
        "        'aus-1',\n",
        "\n",
        "        # Audit Feilds\n",
        "        'derived_sex',\n",
        "        'derived_race',\n",
        "        'derived_ethnicity'\n",
        "       ]]"
      ],
      "metadata": {
        "id": "CW7Aq_wKAG3B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1)"
      ],
      "metadata": {
        "id": "aHqHhjKJALwb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Filtering"
      ],
      "metadata": {
        "id": "-RFZJ5WPAQPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(df[df.action_taken > 3].index).reset_index(drop=True)\n",
        "\n",
        "df = df.drop(df[df.derived_race == 'Free Form Text Only'].index).reset_index(drop=True)\n",
        "df = df.drop(df[df.derived_race == 'Race Not Available'].index).reset_index(drop=True)\n",
        "\n",
        "df = df.drop(df[df.derived_ethnicity == 'Free Form Text Only'].index).reset_index(drop=True)\n",
        "df = df.drop(df[df.derived_ethnicity == 'Ethnicity Not Available'].index).reset_index(drop=True)\n",
        "\n",
        "df = df.drop(df[df.derived_sex == 'Sex Not Available'].index).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "MGC5Vk7NAUFc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessor "
      ],
      "metadata": {
        "id": "XYq0U4CsAbjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = [\n",
        "        'loan_type',\n",
        "        'loan_purpose',\n",
        "        'business_or_commercial_purpose',\n",
        "        'loan_to_value_ratio',\n",
        "        'interest_rate',\n",
        "        'hoepa_status',\n",
        "        'loan_term',\n",
        "        'property_value',\n",
        "        'construction_method',\n",
        "        'occupancy_type',\n",
        "        'income',\n",
        "        'debt_to_income_ratio',\n",
        "        'submission_of_application',\n",
        "        'aus-1'\n",
        "]\n",
        "\n",
        "label_features = ['action_taken']\n",
        "\n",
        "audit_features = [\n",
        "    'derived_sex',\n",
        "    'derived_race',\n",
        "    'derived_ethnicity'\n",
        "]"
      ],
      "metadata": {
        "id": "iWIBG4VOAfcl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['action_taken'] = df['action_taken'].replace(1, 1)\n",
        "df['action_taken'] = df['action_taken'].replace(2, 1)\n",
        "df['action_taken'] = df['action_taken'].replace(3, 0)\n",
        "\n",
        "df['loan_type'] = df['loan_type'].apply(pd.to_numeric)\n",
        "\n",
        "df['loan_purpose'] = df['loan_purpose'].replace(31, 6)\n",
        "df['loan_purpose'] = df['loan_purpose'].replace(32, 7)\n",
        "df['loan_purpose'] = df['loan_purpose'].fillna(0)\n",
        "df['loan_purpose'] = df['loan_purpose'].apply(pd.to_numeric)\n",
        "\n",
        "df['business_or_commercial_purpose'] = df['business_or_commercial_purpose'].replace(1111, 0)\n",
        "df['business_or_commercial_purpose'] = df['business_or_commercial_purpose'].fillna(0)\n",
        "df['business_or_commercial_purpose'] = df['business_or_commercial_purpose'].apply(pd.to_numeric)\n",
        "\n",
        "df['loan_to_value_ratio'] = df['loan_to_value_ratio'].replace('Exempt', 0.0)\n",
        "df['loan_to_value_ratio'] = df['loan_to_value_ratio'].fillna(0.0)\n",
        "df['loan_to_value_ratio'] = df['loan_to_value_ratio'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['interest_rate'] = df['interest_rate'].replace('Exempt', -1.0)\n",
        "df['interest_rate'] = df['interest_rate'].fillna(-1)\n",
        "df['interest_rate'] = df['interest_rate'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['hoepa_status'] = df['hoepa_status'].fillna(0)\n",
        "df['hoepa_status'] = df['hoepa_status'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['loan_term'] = df['loan_term'].replace('Exempt', 0)\n",
        "df['loan_term'] = df['loan_term'].fillna(0)\n",
        "df['loan_term'] = df['loan_term'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['property_value'] = df['property_value'].replace('Exempt', 0)\n",
        "df['property_value'] = df['property_value'].fillna(0)\n",
        "df['property_value'] = df['property_value'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['construction_method'] = df['construction_method'].fillna(0)\n",
        "df['construction_method'] = df['construction_method'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['income'] = df['income'].fillna(0)\n",
        "df['occupancy_type'] = df['occupancy_type'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['income'] = df['income'].fillna(0)\n",
        "df['income'] = df['income'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('Exempt',   0)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('20%-<30%', 1)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('30%-<36%', 2)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('36',       3)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('37',       4)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('38',       5)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('39',       6)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('40',       7)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('41',       8)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('42',       9)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('43',      10)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('44',      11)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('45',      12)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('46',      13)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('47',      14)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('48',      15)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('49',      16)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('50%-60%', 17)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('<20%',    18)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace('>60%',    19)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].fillna(0)\n",
        "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['submission_of_application'] = df['submission_of_application'].replace(1111,  0)\n",
        "df['submission_of_application'] = df['submission_of_application'].fillna(0)\n",
        "df['submission_of_application'] = df['submission_of_application'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df['aus-1'] = df['aus-1'].replace(1111,  0)\n",
        "df['aus-1'] = df['aus-1'].fillna(0)\n",
        "df['aus-1'] = df['aus-1'].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "FO-0LSNIAlLx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['loan_type']]                      = StandardScaler().fit_transform(df[['loan_type']])\n",
        "df[['loan_purpose']]                   = StandardScaler().fit_transform(df[['loan_purpose']])\n",
        "df[['business_or_commercial_purpose']] = StandardScaler().fit_transform(df[['business_or_commercial_purpose']])\n",
        "df[['loan_to_value_ratio']]            = StandardScaler().fit_transform(df[['loan_to_value_ratio']])\n",
        "df[['interest_rate']]                  = StandardScaler().fit_transform(df[['interest_rate']])\n",
        "df[['hoepa_status']]                   = StandardScaler().fit_transform(df[['hoepa_status']])\n",
        "df[['loan_term']]                      = StandardScaler().fit_transform(df[['loan_term']])\n",
        "df[['property_value']]                 = StandardScaler().fit_transform(df[['property_value']])\n",
        "df[['construction_method']]            = StandardScaler().fit_transform(df[['construction_method']])\n",
        "df[['occupancy_type']]                 = StandardScaler().fit_transform(df[['occupancy_type']])\n",
        "df[['income']]                         = StandardScaler().fit_transform(df[['income']])\n",
        "df[['debt_to_income_ratio']]           = StandardScaler().fit_transform(df[['debt_to_income_ratio']])\n",
        "df[['submission_of_application']]      = StandardScaler().fit_transform(df[['submission_of_application']])\n",
        "df[['aus-1']]                          = StandardScaler().fit_transform(df[['aus-1']])"
      ],
      "metadata": {
        "id": "ncOsDWTeAo4Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in input_features:\n",
        "    print(f\"feature {feature:32} mean/std = {df[feature].mean():+02.2f} / {df[feature].std():+02.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXu9wj1aAsQw",
        "outputId": "e9e8a9d8-93a0-41d7-cec6-f90ba6e334b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature loan_type                        mean/std = +0.00 / +1.00\n",
            "feature loan_purpose                     mean/std = -0.00 / +1.00\n",
            "feature business_or_commercial_purpose   mean/std = +0.00 / +1.00\n",
            "feature loan_to_value_ratio              mean/std = -0.00 / +1.00\n",
            "feature interest_rate                    mean/std = -0.00 / +1.00\n",
            "feature hoepa_status                     mean/std = +0.00 / +1.00\n",
            "feature loan_term                        mean/std = +0.00 / +1.00\n",
            "feature property_value                   mean/std = -0.00 / +1.00\n",
            "feature construction_method              mean/std = -0.00 / +1.00\n",
            "feature occupancy_type                   mean/std = -0.00 / +1.00\n",
            "feature income                           mean/std = -0.00 / +1.00\n",
            "feature debt_to_income_ratio             mean/std = +0.00 / +1.00\n",
            "feature submission_of_application        mean/std = -0.00 / +1.00\n",
            "feature aus-1                            mean/std = -0.00 / +1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTHSvOL1AvmZ",
        "outputId": "9b22e8a0-c37e-45b2-b8bb-4750e288d21e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "action_taken                        int64\n",
              "loan_type                         float64\n",
              "loan_purpose                      float64\n",
              "business_or_commercial_purpose    float64\n",
              "loan_to_value_ratio               float64\n",
              "interest_rate                     float64\n",
              "hoepa_status                      float64\n",
              "loan_term                         float64\n",
              "property_value                    float64\n",
              "construction_method               float64\n",
              "occupancy_type                    float64\n",
              "income                            float64\n",
              "debt_to_income_ratio              float64\n",
              "submission_of_application         float64\n",
              "aus-1                             float64\n",
              "derived_sex                        object\n",
              "derived_race                       object\n",
              "derived_ethnicity                  object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = path + 'df.csv'\n",
        "df.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weYDCr5jA2X1",
        "outputId": "d1e45b8a-60e9-4d4e-cd95-27097f115567"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/df.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting"
      ],
      "metadata": {
        "id": "qAmfu-aaBA46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_input = df[input_features]\n",
        "df_label = df[label_features]\n",
        "df_audit = df[audit_features]"
      ],
      "metadata": {
        "id": "S0kQCQFpBDT0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = path + 'df-input.csv'\n",
        "df_input.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "filename = path + 'df-label.csv'\n",
        "df_label.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "filename = path + 'df-audit.csv'\n",
        "df_audit.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjp-_hK_BNGk",
        "outputId": "a056a9da-6438-4cf5-e0e5-e0b525a1e11f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/df-input.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/df-label.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/df-audit.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(df)\n",
        "split_index = int(0.75 * n)\n",
        "x_train = df_input[:split_index]\n",
        "x_test  = df_input[split_index+1:]\n",
        "y_train = df_label[:split_index]\n",
        "y_test  = df_label[split_index+1:]\n",
        "z_train = df_audit[:split_index]\n",
        "z_test  = df_audit[split_index+1:]\n",
        "\n",
        "print(f\"x_train = {x_train.shape}\")\n",
        "print(f\"y_train = {y_train.shape}\")\n",
        "print(f\"z_train = {z_train.shape}\")\n",
        "print(f\"x_test  = {x_test.shape}\")\n",
        "print(f\"y_test  = {y_test.shape}\")\n",
        "print(f\"z_test  = {z_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buIFH-HHBROw",
        "outputId": "dc4c04f9-ea5c-4a00-8f84-f4dba4648c54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train = (565132, 14)\n",
            "y_train = (565132, 1)\n",
            "z_train = (565132, 3)\n",
            "x_test  = (188377, 14)\n",
            "y_test  = (188377, 1)\n",
            "z_test  = (188377, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = path + 'x_train.csv'\n",
        "x_train.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "filename = path + 'x_test.csv'\n",
        "x_test.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "\n",
        "filename = path + 'y_train.csv'\n",
        "y_train.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "filename = path + 'y_test.csv'\n",
        "y_test.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "\n",
        "filename = path + 'z_train.csv'\n",
        "z_train.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)\n",
        "\n",
        "filename = path + 'z_test.csv'\n",
        "z_test.to_csv(filename, index=False)\n",
        "print('Data Saved to:', filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfitBej5BU6e",
        "outputId": "a38c956d-f74f-4b55-d499-efd6e60645f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/x_train.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/x_test.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/y_train.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/y_test.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/z_train.csv\n",
            "Data Saved to: /content/drive/MyDrive/CS510_CulturalCompetenceInComputing/Final submission/z_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Model"
      ],
      "metadata": {
        "id": "iU14T9D_Bcgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training(x, y, feature_selection, epochs, batch_size):\n",
        "    x_train, x_test = x[0], x[1]\n",
        "    y_train, y_test = y[0], y[1]\n",
        "\n",
        "    x_train = x_train[feature_selection].to_numpy()\n",
        "    x_test  = x_test[feature_selection].to_numpy()\n",
        "    y_train = y_train.to_numpy()\n",
        "    y_test  = y_test.to_numpy()\n",
        "\n",
        "    feature_count = len(feature_selection)\n",
        "\n",
        "    # define the keras model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_shape=(feature_count,), activation='tanh'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    metrics = ['accuracy']\n",
        "\n",
        "    # compile the keras model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\n",
        "\n",
        "    # print the model summary\n",
        "    print()\n",
        "    model.summary()\n",
        "    print()\n",
        "\n",
        "    # fit the keras model on the dataset\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    print()\n",
        "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "    print(f\"y_pred.shape = {y_pred.shape}\")\n",
        "    print()\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print()\n",
        "    tn, fp, fn, tp = cm.ravel() # from the docs\n",
        "    print(f\"tp = {tp:8} ~ {tp/cm.sum()*100:06.3f}%\")\n",
        "    print(f\"tn = {tn:8} ~ {tn/cm.sum()*100:06.3f}%\")\n",
        "    print(f\"fp = {fp:8} ~ {fp/cm.sum()*100:06.3f}%\")\n",
        "    print(f\"fn = {fn:8} ~ {fn/cm.sum()*100:06.3f}%\")\n",
        "    print()\n",
        "    print(\"Sensitivity (true positive rate) refers to the probability of a positive test, conditioned on truly being positive.\")\n",
        "    print(f\"Sensitivity (tpr) = {tp:8} / {tp+fn:8} ~ {tp/(tp+fn)*100:06.3f}%\")\n",
        "    print(\"Specificity (true negative rate) refers to the probability of a negative test, conditioned on truly being negative.\")\n",
        "    print(f\"Specificity (tnr) = {tn:8} / {tn+fp:8} ~ {tn/(tn+fp)*100:06.3f}%\")\n",
        "\n",
        "    return model, y_pred"
      ],
      "metadata": {
        "id": "mRNhK7wHBemG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "deWbL3ZlBlp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = [\n",
        "    'loan_type',\n",
        "    'loan_purpose',\n",
        "    'business_or_commercial_purpose',\n",
        "    'loan_to_value_ratio',\n",
        "    #'interest_rate',\n",
        "    'hoepa_status',\n",
        "    #'loan_term',\n",
        "    'property_value',\n",
        "    'construction_method', \n",
        "    'occupancy_type',\n",
        "    'income',\n",
        "    'debt_to_income_ratio',\n",
        "    'submission_of_application',\n",
        "    'aus-1'\n",
        "]\n",
        "\n",
        "model, prediction = model_training((x_train, x_test), (y_train, y_test), feature_list, epochs=10, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtzcZBciBrft",
        "outputId": "c9eeaa93-c13d-4ef4-db0a-fc022b47a2cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 113\n",
            "Trainable params: 113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1/10\n",
            "2208/2208 [==============================] - 6s 2ms/step - loss: 0.1662 - accuracy: 0.9360\n",
            "Epoch 2/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1075 - accuracy: 0.9511\n",
            "Epoch 3/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1051 - accuracy: 0.9520\n",
            "Epoch 4/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1041 - accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1033 - accuracy: 0.9532\n",
            "Epoch 6/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1028 - accuracy: 0.9533\n",
            "Epoch 7/10\n",
            "2208/2208 [==============================] - 5s 2ms/step - loss: 0.1023 - accuracy: 0.9534\n",
            "Epoch 8/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1020 - accuracy: 0.9534\n",
            "Epoch 9/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1018 - accuracy: 0.9535\n",
            "Epoch 10/10\n",
            "2208/2208 [==============================] - 4s 2ms/step - loss: 0.1016 - accuracy: 0.9536\n",
            "\n",
            "5887/5887 [==============================] - 6s 1ms/step\n",
            "y_pred.shape = (188377, 1)\n",
            "\n",
            "[[ 25002   2646]\n",
            " [  6019 154710]]\n",
            "\n",
            "tp =   154710 ~ 82.128%\n",
            "tn =    25002 ~ 13.272%\n",
            "fp =     2646 ~ 01.405%\n",
            "fn =     6019 ~ 03.195%\n",
            "\n",
            "Sensitivity (true positive rate) refers to the probability of a positive test, conditioned on truly being positive.\n",
            "Sensitivity (tpr) =   154710 /   160729 ~ 96.255%\n",
            "Specificity (true negative rate) refers to the probability of a negative test, conditioned on truly being negative.\n",
            "Specificity (tnr) =    25002 /    27648 ~ 90.430%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Processing"
      ],
      "metadata": {
        "id": "56SSUmGiCGTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = pd.DataFrame()\n",
        "\n",
        "for column in x_test:\n",
        "    df_output[column] = x_test[column]\n",
        "\n",
        "df_output['label_value'] = y_test\n",
        "\n",
        "df_output['score'] = prediction\n",
        "\n",
        "for column in z_test:\n",
        "    df_output[column] = z_test[column]\n",
        "\n",
        "df_output = df_output.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nB8FoGraCNs6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Measurements"
      ],
      "metadata": {
        "id": "qrLecXCLCQYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "approved_list = df.action_taken == 1\n",
        "approval_count = len(df[approved_list].reset_index(drop=True))\n",
        "approval_rate = approval_count / len(df) * 100\n",
        "print(f\"the overall approval rate is {approval_rate:05.2f}%, which is {approval_count} approvals over {len(df)} applications\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ht2kmvFCU2-",
        "outputId": "d13c0030-0948-4410-ee17-3fc75e434d23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the overall approval rate is 85.23%, which is 642233 approvals over 753510 applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def approval_rate_by_chosen_field(df, chosen_field, ref):\n",
        "    field_group = df.groupby(by=chosen_field)\n",
        "    #print(field_group.size())\n",
        "    #print(field_group.size().sum())\n",
        "\n",
        "    group_count = len(field_group)\n",
        "    print(f\"We have {group_count} groups of values in '{chosen_field}'\")\n",
        "    print()\n",
        "\n",
        "    TP = [None] * group_count\n",
        "    TN = [None] * group_count\n",
        "    FP = [None] * group_count\n",
        "    FN = [None] * group_count\n",
        "    PP = [None] * group_count\n",
        "    PN = [None] * group_count\n",
        "    P  = [None] * group_count\n",
        "    N  = [None] * group_count\n",
        "\n",
        "    TPR = [None] * group_count\n",
        "    FPR = [None] * group_count\n",
        "    TNR = [None] * group_count\n",
        "    FNR = [None] * group_count\n",
        "    FDR = [None] * group_count\n",
        "    FOR = [None] * group_count\n",
        "    PPV = [None] * group_count\n",
        "    NPV = [None] * group_count\n",
        "\n",
        "    GSR  = [None] * group_count\n",
        "    PPR  = [None] * group_count\n",
        "    PPGR = [None] * group_count\n",
        "\n",
        "    for i, group_name in enumerate(field_group.groups):\n",
        "        # find the index of 'ref' on our first loop through the groups.\n",
        "        #   used in the next loop to give disparity rates.\n",
        "        if group_name == ref: j = i\n",
        "\n",
        "        y = df[chosen_field] == group_name\n",
        "        y_pred = df[y]['score'].reset_index(drop=True)\n",
        "        y_test = df[y]['label_value'].reset_index(drop=True)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        TN[i], FP[i], FN[i], TP[i] = cm.ravel() # from the docs\n",
        "        PP[i] = FP[i] + TP[i] # used\n",
        "        PN[i] = FN[i] + TN[i] # used\n",
        "        P[i]  = TP[i] + FN[i] # used\n",
        "        N[i]  = FP[i] + TN[i] # used\n",
        "\n",
        "        #TPR[i] = TP[i] /  P[i]\n",
        "        FPR[i] = FP[i] /  N[i] # used\n",
        "        #TNR[i] = TN[i] /  N[i]\n",
        "        FNR[i] = FN[i] /  P[i] # used\n",
        "        FDR[i] = FP[i] / PP[i] # used\n",
        "        FOR[i] = FN[i] / PN[i] # used\n",
        "        #PPV[i] = TP[i] / PP[i]\n",
        "        #NPV[i] = TN[i] / PN[i]\n",
        "\n",
        "    print('Group Metrics---------------------------------------------------------------------------------------------------------------------------')\n",
        "    for i, group_name in enumerate(field_group.groups):\n",
        "        group_size = len(df[df[chosen_field] == group_name])\n",
        "        GSR[i]  = group_size/len(df)\n",
        "        PPR[i]  = PP[i]/sum(PP)\n",
        "        PPGR[i] = PP[i]/group_size\n",
        "\n",
        "        print(f\"{group_name:50}  \", end='')\n",
        "        print(f\"GSR = {GSR[i]:04.2f}  \", end='')\n",
        "        print(f\"PPR = {PPR[i]:04.2f}  \", end='')\n",
        "        print(f\"PPGR = {PPGR[i]:04.2f}  \", end='')\n",
        "        print(f\"FDR = {FDR[i]:04.2f}  \", end='')\n",
        "        print(f\"FPR = {FPR[i]:04.2f}  \", end='')\n",
        "        print(f\"FOR = {FOR[i]:04.2f}  \", end='')\n",
        "        print(f\"FNR = {FNR[i]:04.2f}  \", end='')\n",
        "        print()\n",
        "\n",
        "    print('Disparity/Bias Metrics------------------------------------------------------------------------------------------------------------------')\n",
        "    for i, group_name in enumerate(field_group.groups):\n",
        "        print(f\"{group_name:50}  \", end='')\n",
        "        print(f\"PPR_d  = {PPR[i] / PPR[j]:04.2f}  \", end='')\n",
        "        print(f\"PPGR_d = {PPGR[i] / PPGR[j]:04.2f}  \", end='')\n",
        "        print(f\"FDR_d = {FDR[i] / FDR[j]:04.2f}  \", end='')\n",
        "        print(f\"FPR_d = {FPR[i] / FPR[j]:04.2f}  \", end='')\n",
        "        print(f\"FOR_d = {FOR[i] / FOR[j]:04.2f}  \", end='')\n",
        "        print(f\"FNR_d = {FNR[i] / FNR[j]:04.2f}  \", end='')\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "vVncX1DZCqtX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "approval_rate_by_chosen_field(df_output, chosen_field = 'derived_sex', ref='Male')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEhdNkBKCwh8",
        "outputId": "bac18f25-4f8b-4983-d4f3-cf66a8335b84"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 3 groups of values in 'derived_sex'\n",
            "\n",
            "Group Metrics---------------------------------------------------------------------------------------------------------------------------\n",
            "Female                                              GSR = 0.22  PPR = 0.21  PPGR = 0.81  FDR = 0.02  FPR = 0.09  FOR = 0.18  FNR = 0.04  \n",
            "Joint                                               GSR = 0.49  PPR = 0.50  PPGR = 0.86  FDR = 0.01  FPR = 0.10  FOR = 0.21  FNR = 0.03  \n",
            "Male                                                GSR = 0.30  PPR = 0.29  PPGR = 0.81  FDR = 0.02  FPR = 0.09  FOR = 0.18  FNR = 0.04  \n",
            "Disparity/Bias Metrics------------------------------------------------------------------------------------------------------------------\n",
            "Female                                              PPR_d  = 0.73  PPGR_d = 1.00  FDR_d = 0.91  FPR_d = 0.92  FOR_d = 1.00  FNR_d = 0.98  \n",
            "Joint                                               PPR_d  = 1.76  PPGR_d = 1.07  FDR_d = 0.69  FPR_d = 1.09  FOR_d = 1.19  FNR_d = 0.78  \n",
            "Male                                                PPR_d  = 1.00  PPGR_d = 1.00  FDR_d = 1.00  FPR_d = 1.00  FOR_d = 1.00  FNR_d = 1.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "approval_rate_by_chosen_field(df_output, chosen_field = 'derived_race', ref='White')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "319YGmk_CzT1",
        "outputId": "d7dc248e-1b4f-4f7e-bfcb-47d69902b225"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 7 groups of values in 'derived_race'\n",
            "\n",
            "Group Metrics---------------------------------------------------------------------------------------------------------------------------\n",
            "2 or more minority races                            GSR = 0.00  PPR = 0.00  PPGR = 0.74  FDR = 0.02  FPR = 0.06  FOR = 0.09  FNR = 0.03  \n",
            "American Indian or Alaska Native                    GSR = 0.01  PPR = 0.01  PPGR = 0.73  FDR = 0.02  FPR = 0.07  FOR = 0.15  FNR = 0.05  \n",
            "Asian                                               GSR = 0.05  PPR = 0.05  PPGR = 0.82  FDR = 0.03  FPR = 0.13  FOR = 0.16  FNR = 0.03  \n",
            "Black or African American                           GSR = 0.01  PPR = 0.01  PPGR = 0.77  FDR = 0.03  FPR = 0.10  FOR = 0.13  FNR = 0.04  \n",
            "Joint                                               GSR = 0.03  PPR = 0.04  PPGR = 0.86  FDR = 0.02  FPR = 0.11  FOR = 0.19  FNR = 0.03  \n",
            "Native Hawaiian or Other Pacific Islander           GSR = 0.00  PPR = 0.00  PPGR = 0.76  FDR = 0.03  FPR = 0.10  FOR = 0.15  FNR = 0.04  \n",
            "White                                               GSR = 0.89  PPR = 0.89  PPGR = 0.84  FDR = 0.02  FPR = 0.09  FOR = 0.20  FNR = 0.04  \n",
            "Disparity/Bias Metrics------------------------------------------------------------------------------------------------------------------\n",
            "2 or more minority races                            PPR_d  = 0.00  PPGR_d = 0.89  FDR_d = 1.36  FPR_d = 0.69  FOR_d = 0.47  FNR_d = 0.86  \n",
            "American Indian or Alaska Native                    PPR_d  = 0.01  PPGR_d = 0.87  FDR_d = 1.52  FPR_d = 0.78  FOR_d = 0.76  FNR_d = 1.43  \n",
            "Asian                                               PPR_d  = 0.06  PPGR_d = 0.98  FDR_d = 1.69  FPR_d = 1.40  FOR_d = 0.82  FNR_d = 0.91  \n",
            "Black or African American                           PPR_d  = 0.01  PPGR_d = 0.92  FDR_d = 1.72  FPR_d = 1.05  FOR_d = 0.68  FNR_d = 1.03  \n",
            "Joint                                               PPR_d  = 0.04  PPGR_d = 1.02  FDR_d = 1.08  FPR_d = 1.20  FOR_d = 0.94  FNR_d = 0.82  \n",
            "Native Hawaiian or Other Pacific Islander           PPR_d  = 0.00  PPGR_d = 0.91  FDR_d = 1.89  FPR_d = 1.10  FOR_d = 0.74  FNR_d = 1.18  \n",
            "White                                               PPR_d  = 1.00  PPGR_d = 1.00  FDR_d = 1.00  FPR_d = 1.00  FOR_d = 1.00  FNR_d = 1.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "approval_rate_by_chosen_field(df_output, chosen_field = 'derived_ethnicity', ref='Not Hispanic or Latino')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDjh9AUJC1rM",
        "outputId": "6e2c4dd5-6132-4afd-fbe9-f4a505c60bc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 3 groups of values in 'derived_ethnicity'\n",
            "\n",
            "Group Metrics---------------------------------------------------------------------------------------------------------------------------\n",
            "Hispanic or Latino                                  GSR = 0.05  PPR = 0.04  PPGR = 0.77  FDR = 0.02  FPR = 0.09  FOR = 0.16  FNR = 0.05  \n",
            "Joint                                               GSR = 0.03  PPR = 0.03  PPGR = 0.84  FDR = 0.01  FPR = 0.08  FOR = 0.19  FNR = 0.04  \n",
            "Not Hispanic or Latino                              GSR = 0.92  PPR = 0.93  PPGR = 0.84  FDR = 0.02  FPR = 0.10  FOR = 0.20  FNR = 0.04  \n",
            "Disparity/Bias Metrics------------------------------------------------------------------------------------------------------------------\n",
            "Hispanic or Latino                                  PPR_d  = 0.05  PPGR_d = 0.92  FDR_d = 1.40  FPR_d = 0.88  FOR_d = 0.83  FNR_d = 1.27  \n",
            "Joint                                               PPR_d  = 0.03  PPGR_d = 1.00  FDR_d = 0.80  FPR_d = 0.83  FOR_d = 0.98  FNR_d = 0.96  \n",
            "Not Hispanic or Latino                              PPR_d  = 1.00  PPGR_d = 1.00  FDR_d = 1.00  FPR_d = 1.00  FOR_d = 1.00  FNR_d = 1.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report\n",
        "\n",
        "http://aequitas.dssg.io/audit/tf3owqzf/df_output_with-bias-mitigation/report-1.html"
      ],
      "metadata": {
        "id": "c4qcKVSlC5Mb"
      }
    }
  ]
}